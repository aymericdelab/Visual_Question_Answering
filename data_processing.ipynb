{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook only deals with the pre-processing of the data locally, which is then uploaded to our Google Colab notebooks for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1a: Sentence embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading our csv file we can see that our questions and answers are arranged in a difficult way. The best would be to have one column with the question, another one with the image it refers to and a third one with the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is on the right side of the black telephone and on the left side of the red chair in the image3 ?\n",
      "desk\n",
      "what is in front of the white door on the left side of the desk in the image3 ?\n",
      "telephone\n",
      "what is on the desk in the image3 ?\n",
      "book  scissor  papers  tape_dispenser\n",
      "what is the largest brown objects in this image3 ?\n",
      "carton\n",
      "what color is the chair in front of the white wall in the image3 ?\n",
      "red\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is on the right side of the black telepho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>desk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is in front of the white door on the left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is on the desk in the image3 ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  what is on the right side of the black telepho...\n",
       "1                                               desk\n",
       "2  what is in front of the white door on the left...\n",
       "3                                          telephone\n",
       "4                what is on the desk in the image3 ?"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##First lets take a sample look at our CSV file\n",
    "\n",
    "# Load the Pandas libraries with alias 'pd' \n",
    "import pandas as pd \n",
    "# Read data from file 'filename.csv' \n",
    "# (in the same directory that your python process is based)\n",
    "# Control delimiters, rows, column names with read_csv (see later) \n",
    "data = pd.read_csv(\"./data/raw_data/DAQUAR_train_raw.csv\",header=None)\n",
    "# Preview the first 5 lines of the loaded data \n",
    "for i in range(10):\n",
    "    print(data[0][i])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The questions are every even row and the answers are every odd row. So we go through each row, check if even or odd and rewrite correctly in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "\n",
    "def prepare_data(in_directory,out_directory, mode):\n",
    "    #find the source and destination directory, mode is either train or test\n",
    "    file_name_in=os.path.join(in_directory,'DAQUAR_{}_raw.csv'.format(str(mode)))\n",
    "    file_name_out=os.path.join(out_directory,'DAQUAR_{}_processed.csv'.format(str(mode)))\n",
    "    \n",
    "    #open the files and read\n",
    "    with open(file_name_in, 'r') as f, open(file_name_out, 'w', newline='') as f_out:\n",
    "        reader = csv.reader(f)\n",
    "        \n",
    "        fieldnames=['question','image','answer']\n",
    "        writer = csv.DictWriter(f_out, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        \n",
    "        #question row, then answer row\n",
    "        row_skip=2\n",
    "        dico={'question':None,\n",
    "              'image':None,\n",
    "              'answer':None}\n",
    "\n",
    "        for index, row in enumerate(reader):\n",
    "            \n",
    "            #even number = question\n",
    "            if index % row_skip ==0:\n",
    "                #split the question at the 'image' key word\n",
    "                question_image_list=row[0].split('image')\n",
    "\n",
    "                dico['question']=[question_image_list[0]]\n",
    "                \n",
    "                #remove the question-mark and rewrite 'image' -> useful for integrating visual features later\n",
    "                dico['image']='image'+question_image_list[1].replace(' ?','')\n",
    "            \n",
    "            else:\n",
    "                dico['answer']=row\n",
    "                \n",
    "                #write row in the csv\n",
    "                writer.writerow({'question': dico['question'], 'image':dico['image'], 'answer': dico['answer']})\n",
    "\n",
    "                dico={'question':None,\n",
    "                 'image':None,\n",
    "                'answer':None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data(in_directory='./data/raw_data', out_directory='./data/processed_data', mode='train')\n",
    "prepare_data(in_directory='./data/raw_data', out_directory='./data/processed_data', mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>question</td>\n",
       "      <td>image</td>\n",
       "      <td>answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['﻿what is on the right side of the black tele...</td>\n",
       "      <td>image3</td>\n",
       "      <td>['desk']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['what is in front of the white door on the le...</td>\n",
       "      <td>image3</td>\n",
       "      <td>['telephone']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['what is on the desk in the ']</td>\n",
       "      <td>image3</td>\n",
       "      <td>['book  scissor  papers  tape_dispenser']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['what is the largest brown objects in this ']</td>\n",
       "      <td>image3</td>\n",
       "      <td>['carton']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1  \\\n",
       "0                                           question   image   \n",
       "1  ['﻿what is on the right side of the black tele...  image3   \n",
       "2  ['what is in front of the white door on the le...  image3   \n",
       "3                    ['what is on the desk in the ']  image3   \n",
       "4     ['what is the largest brown objects in this ']  image3   \n",
       "\n",
       "                                           2  \n",
       "0                                     answer  \n",
       "1                                   ['desk']  \n",
       "2                              ['telephone']  \n",
       "3  ['book  scissor  papers  tape_dispenser']  \n",
       "4                                 ['carton']  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"./data/processed_data/DAQUAR_train_processed.csv\",header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1b: Create GloVe word embedding array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only used if you don't want to create a custom embedding for your words. In autoencoder1 we use a custom 300d embeddings for words, which is found while training the autoencoder. In autoencoder2 we use a pre-trained embedding, trained on a very very large amount of text. Because we don't want to load the whole GloVe file on google colab, we first process it locally so that it only incorporates the words of our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## read the csv files with the data\n",
    "\n",
    "train_dir='./data/processed_data/DAQUAR_train_processed.csv'\n",
    "test_dir='./data/processed_data/DAQUAR_test_processed.csv'\n",
    "\n",
    "data_train=pd.read_csv(train_dir)\n",
    "data_test=pd.read_csv(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Aymeric\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Make sure that our version of tensorflow is not 2.0\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#create an instance of class Tokenizer\n",
    "MAX_WORDS = 3000\n",
    "tokenizer = Tokenizer(num_words = MAX_WORDS, split=' ')\n",
    "\n",
    "#has to fit on questions and answers of the train dataset only\n",
    "tokenizer.fit_on_texts(data_train['question'])\n",
    "tokenizer.fit_on_texts(data_train['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Because GloVe has about 400K words in its vocabulary, the size of the file is very heavy. \n",
    "## Thus we first load GloVe locally to extract the words that are present in our training vocabulary\n",
    "## and save it as a numpy file. Then we load it on Google Colab. We go from a 1GB file to a 3.6MB file\n",
    "\n",
    "def create_embedding_matrix(tokenizer,directory,embed_dims):\n",
    "    embeddings_index = {}\n",
    "    #first download the glove data for 300 dimensions here : https://nlp.stanford.edu/projects/glove/\n",
    "    #the file is glove.6B.zip and inside you have glove.6B.300d.txt\n",
    "    with open(directory,encoding='utf8') as f:\n",
    "        #processing the text\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    \n",
    "    #get the list of words that we have in the training set\n",
    "    word_index=tokenizer.word_index.items()\n",
    "    #number of dimensions for the glove embedding (depends on which file you donwloaded, here 300)\n",
    "    EMBEDDING_DIM=embed_dims\n",
    "    \n",
    "    #create an empty matrix that we are going to fill\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index:\n",
    "        #get the glove embedding for the word\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory='./data/embedding/glove.6B.300d.txt'\n",
    "embed_dims=300\n",
    "\n",
    "embedding_matrix=create_embedding_matrix(tokenizer, directory,embed_dims)\n",
    "#save it as an npy file so that we can load it in Google Colab\n",
    "np.save('./data/embedding/glove_300d_embedding.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Visual Features\n",
    "\n",
    "We get the visual features obtained from one of the last layers of VGG19. And attach each of these features to the correct question/answer as a tuple in a deque, which is like a list but more powerful. The deque file will then be loaded into memory on our Colab notebook in order to train our question-answering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REDO THE SAME STEPS AS PREVIOUSLY\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "## read the csv files with the data\n",
    "\n",
    "train_dir='./data/processed_data/DAQUAR_train_processed.csv'\n",
    "test_dir='./data/processed_data/DAQUAR_test_processed.csv'\n",
    "\n",
    "data_train=pd.read_csv(train_dir)\n",
    "data_test=pd.read_csv(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "# Make sure that our version of tensorflow is not 2.0\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#create an instance of class Tokenizer\n",
    "MAX_WORDS = 3000\n",
    "tokenizer = Tokenizer(num_words = MAX_WORDS, split=' ')\n",
    "\n",
    "#has to fit on questions and answers of the train dataset only\n",
    "\n",
    "tokenizer.fit_on_texts(data_train['question'])\n",
    "tokenizer.fit_on_texts(data_train['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#the tokenizer must already be fit on your training text\n",
    "def tokenization(tokenizer, length_of_sequence, dataset, multiple_answer=True):\n",
    "    MAX_LEN=length_of_sequence\n",
    "\n",
    "    seqs_question = tokenizer.texts_to_sequences(dataset['question'])\n",
    "    seqs_answer = tokenizer.texts_to_sequences(dataset['answer'])\n",
    "\n",
    "    #when you pad as 'post' you will remove the words at the end of the sentence if too long, and not at the start\n",
    "    #of the sentence.\n",
    "    pad_seqs_question = pad_sequences(seqs_question,MAX_LEN,truncating='post')\n",
    "    pad_seqs_answer = pad_sequences(seqs_answer,MAX_LEN,truncating='post')\n",
    "\n",
    "    #we choose if we want to keep one or multiple answers\n",
    "    if multiple_answer is False:\n",
    "        pad_seqs_answer_one_answer = pad_seqs_answer[:,[MAX_LEN-1]]\n",
    "        return pad_seqs_question, dataset['image'], pad_seqs_answer_one_answer\n",
    "\n",
    "    else:\n",
    "        return pad_seqs_question, dataset['image'], pad_seqs_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we set the max number of words in each questin to 25, if less than 25 there will be padding (zeros)\n",
    "MAX_LEN=25\n",
    "\n",
    "### TRAINING SET ####\n",
    "train_questions,train_images,train_answers = tokenization(tokenizer, MAX_LEN, data_train, multiple_answer=False)\n",
    "test_questions,test_images,test_answers = tokenization(tokenizer, MAX_LEN, data_test, multiple_answer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the json file that has all the visual features we need for each image. It's a dictionary and you can call an image by using 'imageX'.\n",
    "\n",
    "\n",
    "ex: feat['image3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#load the visual features into memory\n",
    "with open('./data/img_features.json', 'r') as f:\n",
    "    feat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "#Because the image name are sometimes wrongly written we use a try/except and count the number of errors we get\n",
    "def fill_deque_with_data(visual_features,questions,images,answers,a_deque):\n",
    "    \n",
    "    #create error count\n",
    "    error=0\n",
    "    #append the indices of the errors\n",
    "    index_error_images=[]\n",
    "\n",
    "    for i in range(len(questions)):\n",
    "        image_name=images[i]\n",
    "        try:\n",
    "            #append tuple to the deque list\n",
    "            a_deque.append((questions[i],visual_features[image_name],answers[i]))\n",
    "        except Exception as e:\n",
    "            #print the exception that caused the visual_features to not work\n",
    "            print(e)\n",
    "            error+=1\n",
    "            index_error_images.append(i)\n",
    "\n",
    "    return error, index_error_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'image10 behind the door frame in fornt of the cabinet in the '\n",
      "'image912 close to the wall in the '\n",
      "'image116 close to the shelf in the '\n",
      "'image135 that is on the counter in the '\n",
      "'image139 on the counter in the '\n",
      "'image95 behind the clothes in the '\n",
      "'image114 on the table in the '\n",
      "'image929 in the '\n",
      "'image1007 in the '\n",
      "'image1008 in the '\n",
      "'image1008 in the '\n",
      "'image1035 in the '\n",
      "'image1043 in the '\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "### TRAINING SET ####\n",
    "train_deque=deque()\n",
    "error, index = fill_deque_with_data(visual_features=feat,\n",
    "                                    questions=train_questions,\n",
    "                                    images=train_images,\n",
    "                                    answers=train_answers,\n",
    "                                    a_deque=train_deque)\n",
    "\n",
    "#save as a text file\n",
    "pickleFile = open(\"./data/processed_data/questions-visual_features-train.txt\", 'wb')\n",
    "pickle.dump(train_deque, pickleFile)\n",
    "pickleFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'image1206 on the floor in the '\n",
      "'image1285 on the floor in the '\n",
      "'image1170 which contains some book in the '\n",
      "'image1400 in the mirror reflection in the '\n",
      "'image155 made of in the '\n",
      "'image168 in the '\n",
      "'image1011 in the '\n",
      "'image1407 in the '\n"
     ]
    }
   ],
   "source": [
    "### TEST SET ####\n",
    "test_deque=deque()\n",
    "error, index = fill_deque_with_data(visual_features=feat,\n",
    "                                    questions=test_questions,\n",
    "                                    images=test_images,\n",
    "                                    answers=test_answers,\n",
    "                                    a_deque=test_deque)\n",
    "\n",
    "#save as a text file \n",
    "pickleFile = open(\"./data/processed_data/questions-visual_features-test.txt\", 'wb')\n",
    "pickle.dump(test_deque, pickleFile)\n",
    "pickleFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "vqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
